{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4601,
     "status": "ok",
     "timestamp": 1726766890704,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "jXMd8PPhFWxv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3cXYT_oK436"
   },
   "source": [
    "# Custom DataLoader for Numerical Data (from Pandas)\n",
    "\n",
    "To load numerical data (e.g., from a CSV file or a Pandas DataFrame), we create a custom dataset class that extends torch.utils.data.Dataset. This class should implement three key methods:\n",
    "\n",
    "* __init__: Initializes the dataset.\n",
    "* __len__: Returns the size of the dataset.\n",
    "* __getitem__: Retrieves a sample from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1726767052682,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "zq1XxuS4Nx9i"
   },
   "outputs": [],
   "source": [
    "class NumericalDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (pd.DataFrame or np.array): Features (independent variables).\n",
    "            labels (pd.Series or np.array): Labels (dependent variables).\n",
    "        \"\"\"\n",
    "\n",
    "        # If data is a pandas DataFrame or Series, use .values to convert to NumPy arrays\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            data = data.values\n",
    "        if isinstance(labels, pd.Series):\n",
    "            labels = labels.values\n",
    "\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)  # Convert to torch tensor\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)  # Convert to torch tensor (classification)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # Returns the total number of samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]  # Returns one sample and its label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1876,
     "status": "ok",
     "timestamp": 1726766832392,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "fGDmEBC6UPhR"
   },
   "outputs": [],
   "source": [
    "# Creating dummy values to get this loaded from pytorch custom dataloader\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_list = [\n",
    "    [0.374540, 0.950714, 0.731994, 0.598658, 0],\n",
    "    [0.156019, 0.155995, 0.058084, 0.866176, 1],\n",
    "    [0.601115, 0.708073, 0.020584, 0.969910, 0],\n",
    "    [0.832443, 0.212339, 0.181825, 0.183405, 2],\n",
    "    [0.304242, 0.524756, 0.431945, 0.291229, 1],\n",
    "    [0.611853, 0.139494, 0.292145, 0.366362, 2],\n",
    "    [0.456070, 0.785176, 0.199674, 0.514234, 1],\n",
    "    [0.592415, 0.046450, 0.607545, 0.170524, 0],\n",
    "    [0.065052, 0.948886, 0.965632, 0.808397, 2],\n",
    "    [0.304614, 0.097672, 0.684233, 0.440152, 1],\n",
    "]\n",
    "\n",
    "# Write the list to a CSV file\n",
    "cwd = os.getcwd()\n",
    "csv_file = f'{cwd}/numerical_data_from_list.csv'\n",
    "\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write header\n",
    "    writer.writerow(['feature1', 'feature2', 'feature3', 'feature4', 'target'])\n",
    "    # Write data rows\n",
    "    writer.writerows(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 442,
     "status": "ok",
     "timestamp": 1726769654083,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "uBtme_RcTrdP",
    "outputId": "c754659c-3ea0-41f8-f4df-826b9470de5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.41665375 -1.19766889  1.05757176 -0.94518329]\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 1 1 2 1]\n",
      "<class 'pandas.core.series.Series'>\n",
      "torch.Size([6, 4]) torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# Example numerical dataset\n",
    "cwd = os.getcwd()\n",
    "csv_file = f'{cwd}/numerical_data_from_list.csv'\n",
    "\n",
    "df = pd.read_csv(csv_file)  # Replace with your CSV file\n",
    "X = df.drop('target', axis=1)  # Features\n",
    "y = df['target']  # Labels\n",
    "\n",
    "# Split the data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Normalize features using StandardScaler (optional)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_train[0, :])\n",
    "print(type(X_train))\n",
    "print(y_train.values)\n",
    "print(type(y_train))\n",
    "# Create Dataset objects\n",
    "train_dataset = NumericalDataset(X_train, y_train)\n",
    "val_dataset = NumericalDataset(X_val, y_val)\n",
    "test_dataset = NumericalDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Example: Iterating through batches of the train_loader\n",
    "for data_batch, labels_batch in train_loader:\n",
    "    print(data_batch.shape, labels_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-urDnAufXwci"
   },
   "source": [
    "# NumericalDataset\n",
    "\n",
    "This custom class defines how to read, preprocess, and handle data (e.g., loading, applying transformations).\n",
    "\n",
    "# DataLoader\n",
    "\n",
    "Manages batching, shuffling, and parallel processing for efficient training."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNp8r+S7R8GhSTXM1VuHJYl",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
